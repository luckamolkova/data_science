{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "**Supervised**<br>\n",
    "[Linear Regression](#LinearRegression)<br>\n",
    "[Lasso Regression](#LassoRegression)<br>\n",
    "[Ridge Regression](#RidgeRegression)<br>\n",
    "[Logistic Regression](#LogisticRegression)<br>\n",
    "[Decision Tree](#DecisionTree)<br>\n",
    "[K Nearest Neighbors](#KNN)<br>\n",
    "[Bagging](#Bagging)<br>\n",
    "[Random Forest](#RandomForest)<br>\n",
    "[Gradient Boosting](#GradientBoost)<br>\n",
    "[AdaBoost](#AdaBoost)<br>\n",
    "[SVM](#SVM) (Support Vector Machines)<br>\n",
    "[Tf-Idf](#TfIdf)<br>\n",
    "\n",
    "**Unsupervised**<br>\n",
    "[K Means](#KMeans)<br>\n",
    "[Hierarchical Clustering](#HierarchicalClustering)<br>\n",
    "[PCA](#PCA) (Principal Component Analysis)<br>\n",
    "[SVD](#SVD) (Singular Value Decomposition)<br>\n",
    "[NMF](#NMF) (Non-negative Matrix Factorization)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "y_all = data.target\n",
    "X_all = data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LinearRegression'></a>\n",
    "### Linear Regression\n",
    "\n",
    "[LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) - sklearn <br>\n",
    "[OLS](http://statsmodels.sourceforge.net/devel/generated/statsmodels.regression.linear_model.OLS.html) - statsmodels\n",
    "\n",
    "- supervised\n",
    "- needs intercept: yes (can use fit_intercept=True in sklearn)\n",
    "- needs dummies: yes (drop one)\n",
    "- needs normalization: ?\n",
    "- needs numeric: yes\n",
    "- target type: numeric\n",
    "\n",
    "*get rid of collinear features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.coef_\n",
    "model.intercept_\n",
    "accuracy = model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21647142, -0.11268404, -0.05848178,  0.26393642,  0.5272465 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_intercept = sm.add_constant(X)\n",
    "\n",
    "model = OLS(y,X_intercept)\n",
    "results = model.fit()\n",
    "results.summary()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LassoRegression'></a>\n",
    "### Lasso Regression\n",
    "[Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: yes\n",
    "- needs dummies: yes (drop one)\n",
    "- needs normalization: ?\n",
    "- needs numeric: yes\n",
    "- target type: numeric\n",
    "\n",
    "*alpha is l1 penalty, alpha = 0 is same as linear regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(fit_intercept=True, alpha=1.)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.coef_\n",
    "model.intercept_\n",
    "accuracy = model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='RidgeRegression'></a>\n",
    "### Ridge Regression\n",
    "\n",
    "[Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: yes\n",
    "- needs dummies: yes (drop one)\n",
    "- needs normalization: ?\n",
    "- needs numeric: yes\n",
    "- target type: numeric\n",
    "\n",
    "*alpha is l2 penalty, alpha = 0 is same as linear regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(fit_intercept=True, alpha=1.)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.coef_\n",
    "model.intercept_\n",
    "accuracy = model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LogisticRegression'></a>\n",
    "### Logistic Regression\n",
    "[LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: yes\n",
    "- needs dummies: yes (drop one)\n",
    "- needs normalization: ?\n",
    "- needs numeric: yes\n",
    "- target type: numeric ?\n",
    "\n",
    "*C is inverse of regularization strength (positive float), smaller C means more regularization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(fit_intercept=True,\n",
    "                           penalty='l2', C=10.)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.coef_\n",
    "model.intercept_\n",
    "accuracy = model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DecisionTree'></a>\n",
    "### Decision Tree\n",
    "[DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: no\n",
    "- needs dummies: no, can deal with classes\n",
    "- needs normalization: no\n",
    "- needs numeric: no\n",
    "- target type: class\n",
    "\n",
    "*criterion can be 'gini' or 'entropy'* <br>\n",
    "*max_features can be used to randomize the tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini',\n",
    "                              max_depth=3,\n",
    "                              max_features=None)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.classes_\n",
    "model.feature_importances_\n",
    "model.tree_\n",
    "accuracy = model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to visualize the tree export graphviz (.dot) format to current directory\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(model, out_file='tree.dot')\n",
    "#then use bash command to make it .png file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dot -Tpng tree.dot -o tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./tree.png' width='100'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='KNN'></a>\n",
    "### K Nearest Neighbors\n",
    "[KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: no\n",
    "- needs dummies: ?\n",
    "- needs normalization: ?\n",
    "- needs numeric: ?\n",
    "- target type: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "y_proba = model.predict_proba(X)\n",
    "\n",
    "model.classes_\n",
    "accuracy = model.score(X,y)\n",
    "kneighbors = model.kneighbors(X[0].reshape(1,X[0].shape[0]), return_distance=False) #indices of k nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Bagging'></a>\n",
    "### Bagging\n",
    "[BaggingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) <br>\n",
    "[BaggingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html)\n",
    "\n",
    "*classifier for classification (classes), regressor for regression (continuous values)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='RandomForest'></a>\n",
    "### Random Forest\n",
    "[RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) <br>\n",
    "[RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: no\n",
    "- needs dummies: no, can deal with classes\n",
    "- needs normalization: ?\n",
    "- needs numeric: no\n",
    "- target type: class for classifier, numeric for regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20, criterion='gini', \n",
    "                               max_depth=3, max_features='auto', \n",
    "                               bootstrap=True, oob_score=True,\n",
    "                               random_state=None, warm_start=False)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.estimators_\n",
    "model.feature_importances_\n",
    "model.oob_score_\n",
    "accuracy = model.score(X,y) #regressor returns coefficient of determination R^2 of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GradientBoost'></a>\n",
    "### Gradient Boosting\n",
    "[GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) <br>\n",
    "[GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: no\n",
    "- needs dummies: ?\n",
    "- needs normalization: ?\n",
    "- needs numeric: ?\n",
    "- target type: class for classifier, numeric for regressor\n",
    "\n",
    "*uses **trees*** <br>\n",
    "*loss is loss function to be optimized, 'deviance' is for classification, 'ls' is least squares in regression, 'lad' is least absolute deviation in regression* <br>\n",
    "*learning_rate shrinks the contribution of each tree by learning_rate; lower learning_rate needs more n_estimators* <br>\n",
    "*subsample is fraction of samples for each base learner; smaller than 1.0 results in Stochastic Gradient Boosting (reduction of variance, increase in bias)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                                   n_estimators=100, subsample=1.0,\n",
    "                                   max_depth=3, init=None, \n",
    "                                   random_state=None, max_features=None, \n",
    "                                   verbose=0, max_leaf_nodes=None, warm_start=False)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.estimators_\n",
    "model.feature_importances_\n",
    "accuracy = model.score(X,y) #regressor returns coefficient of determination R^2 of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AdaBoost'></a>\n",
    "### AdaBoost\n",
    "[AdaBoostClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) <br>\n",
    "[AdaBoostRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)\n",
    "\n",
    "- supervised\n",
    "- needs intercept: no\n",
    "- needs dummies: ?\n",
    "- needs normalization: ?\n",
    "- needs numeric: ?\n",
    "- target type: class for classifier, numeric for regressor\n",
    "\n",
    "*can use **trees or any other base estimators*** <br>\n",
    "*learning_rate shrinks the contribution of each estimator by learning_rate; lower learning_rate needs more n_estimators* <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "model = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.estimators_\n",
    "model.feature_importances_\n",
    "accuracy = model.score(X,y) #regressor returns coefficient of determination R^2 of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SVM'></a>\n",
    "### SVM (Support Vector Machines)\n",
    "[SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    "*stands for Support Vector Machines (C-Support Vector Classification)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TfIdf'></a>\n",
    "### Tf-idf\n",
    "[TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "- supervised\n",
    "- needs text data (single feature) as input\n",
    "- target type: none (k-neighbors or k-means or similar method used for prediciton/classification)\n",
    "\n",
    "*stands for Term Frequency - Inverse Document Frequency*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After he slapped two soldiers, US Lieutenant G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fringes of the Fleet is a booklet written ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antarctica, on average, is the coldest, driest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        wiki_content\n",
       "0  After he slapped two soldiers, US Lieutenant G...\n",
       "1  The Fringes of the Fleet is a booklet written ...\n",
       "2  Antarctica, on average, is the coldest, driest..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = pd.DataFrame([['After he slapped two soldiers, US Lieutenant General George S. Patton was sidelined from combat command'],\n",
    "                         ['The Fringes of the Fleet is a booklet written in 1915 by Rudyard Kipling. It contains essays and poems.'],\n",
    "                         ['Antarctica, on average, is the coldest, driest, and windiest continent, and has the highest average elevation of all the continents.']])\n",
    "text_data.columns = ['wiki_content']\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1915</th>\n",
       "      <th>antarctica</th>\n",
       "      <th>average</th>\n",
       "      <th>booklet</th>\n",
       "      <th>coldest</th>\n",
       "      <th>combat</th>\n",
       "      <th>command</th>\n",
       "      <th>contains</th>\n",
       "      <th>continent</th>\n",
       "      <th>continents</th>\n",
       "      <th>...</th>\n",
       "      <th>kipling</th>\n",
       "      <th>lieutenant</th>\n",
       "      <th>patton</th>\n",
       "      <th>poems</th>\n",
       "      <th>rudyard</th>\n",
       "      <th>sidelined</th>\n",
       "      <th>slapped</th>\n",
       "      <th>soldiers</th>\n",
       "      <th>windiest</th>\n",
       "      <th>written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1915  antarctica  average   booklet   coldest    combat   command  \\\n",
       "0  0.000000    0.000000  0.00000  0.000000  0.000000  0.333333  0.333333   \n",
       "1  0.316228    0.000000  0.00000  0.316228  0.000000  0.000000  0.000000   \n",
       "2  0.000000    0.288675  0.57735  0.000000  0.288675  0.000000  0.000000   \n",
       "\n",
       "   contains  continent  continents    ...      kipling  lieutenant    patton  \\\n",
       "0  0.000000   0.000000    0.000000    ...     0.000000    0.333333  0.333333   \n",
       "1  0.316228   0.000000    0.000000    ...     0.316228    0.000000  0.000000   \n",
       "2  0.000000   0.288675    0.288675    ...     0.000000    0.000000  0.000000   \n",
       "\n",
       "      poems   rudyard  sidelined   slapped  soldiers  windiest   written  \n",
       "0  0.000000  0.000000   0.333333  0.333333  0.333333  0.000000  0.000000  \n",
       "1  0.316228  0.316228   0.000000  0.000000  0.000000  0.000000  0.316228  \n",
       "2  0.000000  0.000000   0.000000  0.000000  0.000000  0.288675  0.000000  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='content', lowercase=True, tokenizer=None, \n",
    "                        stop_words='english', use_idf=True)\n",
    "tfidf = vectorizer.fit_transform(text_data['wiki_content'])\n",
    "\n",
    "#each token (word) is turned into a feature, get full list like this\n",
    "vectorizer.get_feature_names()\n",
    "#tfidf is sparse matrix, to print it nicely we can convert it to an array\n",
    "tfidf.toarray()\n",
    "\n",
    "#nice output (only possible for super small sets)\n",
    "pandas_tfidf = pd.DataFrame(tfidf.toarray())\n",
    "pandas_tfidf.columns = vectorizer.get_feature_names()\n",
    "pandas_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='KMeans'></a>\n",
    "### K Means\n",
    "[KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "\n",
    "- unsupervised\n",
    "- needs intercept: no\n",
    "- needs dummies: ?\n",
    "- needs normalization: ?\n",
    "- needs numeric: ?\n",
    "- target type: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=8, init='k-means++', \n",
    "               n_init=10, max_iter=300, tol=0.0001)\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "model.cluster_centers_\n",
    "model.labels_\n",
    "model.inertia_\n",
    "score = model.score(X) #opposite of the value of X on the K-means objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='HierarchicalClustering'></a>\n",
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='content', lowercase=True, tokenizer=None, \n",
    "                        stop_words='english', use_idf=True)\n",
    "tfidf = vectorizer.fit_transform(text_data['wiki_content'])\n",
    "\n",
    "tfidf_array = tfidf.toarray()\n",
    "dist = squareform(pdist(tfidf_array))\n",
    "links = linkage(dist, method= 'complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot as follows\n",
    "#plt.figure(figsize=(15,5))\n",
    "#dendrogram(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='PCA'></a>\n",
    "### PCA (Principal Component Analysis)\n",
    "[PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "Seek r-dimensional basis that best captures the variance in data. Direction with the largest projected variance is the first principal component, orthogonal direction that captures the second largest projected variance is the second principal component etc. In practice eigenvectors of covariance matrix are calculated. **PCA is a special case of SVD.**\n",
    "\n",
    "- unsupervised\n",
    "- dimensionality reduction / topic modelling - set number of latent features up front\n",
    "\n",
    "*sklearn implementation just calls numpy.linalg.svd and reduces the data, keeping r singular values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(n_components=2) #number of dimensions/topics required\n",
    "model.fit(tfidf.toarray())\n",
    "pca = model.transform(tfidf.toarray())\n",
    "\n",
    "sum(model.explained_variance_ratio_) #two features explain 100% of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf shape: (3, 28) - articles, words\n",
      "pca shape:   (3, 2) - articles, topics\n"
     ]
    }
   ],
   "source": [
    "print 'tfidf shape: %s - articles, words' % str(tfidf.toarray().shape)\n",
    "print 'pca shape:   %s - articles, topics' % str(pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SVD'></a>\n",
    "### SVD (Singular Value Decomposition)\n",
    "[SVD](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html)\n",
    "\n",
    "- unsupervised\n",
    "- dimensionality reduction / topic modelling - returns all latent features, we can reduce the number later\n",
    "- very specific use case for recommenders (see [this blog](http://sifter.org/~simon/journal/20061211.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "\n",
    "U, s, V = np.linalg.svd(tfidf.toarray(), full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf shape:              (3, 28) - articles, words\n",
      "U (weights) shape:        (3, 3) - articles, topics\n",
      "s (singular value) shape: (3,) - topics (rank, diagonal of eigenvalues)\n",
      "V (features) shape:       (3, 28) - topics, words\n"
     ]
    }
   ],
   "source": [
    "print 'tfidf shape:              %s - articles, words' % str(tfidf.toarray().shape)\n",
    "print 'U (weights) shape:        %s - articles, topics' % str(U.shape)\n",
    "print 's (singular value) shape: %s - topics (rank, diagonal of eigenvalues)' % str(s.shape)\n",
    "print 'V (features) shape:       %s - topics, words' % str(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf is roughly U.dot(np.diag(s)).dot(V)\n",
    "\n",
    "power = s**2\n",
    "cum_power = (np.cumsum(power))\n",
    "n = sum(cum_power < max(cum_power) * .9) #singular values (topics) needed to retain 90% of the total power\n",
    "\n",
    "#limit data to keep 90% of the total power - everything is sorted, just use first n\n",
    "U_lim = U[:,:n]\n",
    "s_lim = s[:n]\n",
    "V_lim = V[:n,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='NMF'></a>\n",
    "### NMF (Non-negative Matrix Factorization)\n",
    "[NMF](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html)\n",
    "\n",
    "Find two non-negative matrices W(m,r), H(r,n) whose product approximates the non-negative matrix V(m,n). r is set by user and can be substantially smaller than m or n.\n",
    "\n",
    "- unsupervised\n",
    "- dimensionality reduction / topic modelling - set number of latent features up front\n",
    "- needs non-negative matrix\n",
    "- best in class option for many recommendation problems\n",
    "- can fit via ALS (alternating least squares) or SGD (stochastic gradient descent)\n",
    "- regularize data to avoid overfitting\n",
    "\n",
    "*the objective function is minimized with an alternating minimization of W and H*<br>\n",
    "*use X.clip(min=0, max=X.max()) to ensure matrix is non-negative*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0119047619048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=2, max_iter=100) #number of dimensions/topics required\n",
    "W = model.fit_transform(tfidf.toarray())\n",
    "H = model.components_\n",
    "\n",
    "#MSE mean-squared error of (V - WH)\n",
    "print (np.array(tfidf - W.dot(H))**2).mean()\n",
    "\n",
    "#it is the same as norm of (V - WH) divided by number of elements in V\n",
    "#print np.linalg.norm(tfidf - np.dot(W, H)) / tfidf.toarray().size\n",
    "#print (np.array(tfidf - W.dot(H))**2).sum()**(0.5) / tfidf.toarray().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf shape: (3, 28) - articles, words\n",
      "W shape:     (3, 2) - articles, topics\n",
      "H shape:     (2, 28) - topics, words\n"
     ]
    }
   ],
   "source": [
    "print 'tfidf shape: %s - articles, words' % str(tfidf.toarray().shape)\n",
    "print 'W shape:     %s - articles, topics' % str(W.shape)\n",
    "print 'H shape:     %s - topics, words' % str(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
